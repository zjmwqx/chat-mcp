"""
Step7ä¼˜åŒ–æµ‹è¯•ï¼šå®Œæ•´çš„MCPå·¥ä½œæµç¨‹
æµ‹è¯•ä»LLMç”Ÿæˆå·¥å…·è°ƒç”¨å‚æ•°åˆ°å®é™…æ‰§è¡ŒMCPå·¥å…·çš„å®Œæ•´æµç¨‹
"""

import asyncio
import logging
from typing import List

from chat_mcp import (
    callMCPTool,
    execute_mcp_tool_calls,
    complete_mcp_workflow,
    register_server_config,
    parse_tool_use,
    ChatMessage,
    MCPTool,
    MCPServer,
    MCPCallToolResponse,
)
from chat_mcp.ipc_handler import window_api_mcp

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_mock_tools() -> List[MCPTool]:
    """åˆ›å»ºæ¨¡æ‹Ÿçš„MCPå·¥å…·"""
    return [
        MCPTool(
            id="tool_1",
            name="search_arxiv",
            description="Search for academic papers on arXiv",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search query"},
                    "max_results": {
                        "type": "integer",
                        "description": "Maximum results",
                        "default": 10,
                    },
                },
                "required": ["query"],
            },
            server_id="arxiv_server",
            server_name="ArXiv MCP Server",
        ),
        MCPTool(
            id="tool_2",
            name="get_weather",
            description="Get current weather information",
            inputSchema={
                "type": "object",
                "properties": {
                    "location": {"type": "string", "description": "Location name"},
                    "units": {
                        "type": "string",
                        "description": "Temperature units",
                        "default": "celsius",
                    },
                },
                "required": ["location"],
            },
            server_id="weather_server",
            server_name="Weather MCP Server",
        ),
    ]


def create_mock_server() -> MCPServer:
    """åˆ›å»ºæ¨¡æ‹Ÿçš„æœåŠ¡å™¨é…ç½®"""
    return MCPServer(
        id="arxiv_server",
        name="ArXiv MCP Server",
        command="npx",
        args=["-y", "@modelcontextprotocol/server-arxiv"],
    )


async def test_optimized_call_mcp_tool():
    """æµ‹è¯•ä¼˜åŒ–åçš„callMCPToolå‡½æ•°"""
    print("\n=== æµ‹è¯•1: ä¼˜åŒ–åçš„callMCPTool ===")

    # è®¾ç½®æœåŠ¡å™¨å’Œå·¥å…·
    server = create_mock_server()
    register_server_config(server)
    tools = create_mock_tools()

    # æ¨¡æ‹Ÿä»LLMå“åº”ä¸­è§£æå‡ºçš„å‚æ•°
    tool_name = "search_arxiv"
    arguments = {"query": "machine learning transformers", "max_results": 5}

    print(f"è°ƒç”¨å·¥å…·: {tool_name}")
    print(f"å‚æ•°: {arguments}")

    try:
        # ä½¿ç”¨å®é™…å‚æ•°è°ƒç”¨å·¥å…·
        response = await callMCPTool(tool_name, arguments, tools)

        print("âœ… å·¥å…·è°ƒç”¨å®Œæˆ")
        print(f"  æ˜¯å¦é”™è¯¯: {response.isError}")
        print(f"  å“åº”ç±»å‹: {type(response.content)}")

        # éªŒè¯å“åº”æ ¼å¼
        assert isinstance(response, MCPCallToolResponse)
        assert isinstance(response.content, list)

        if response.isError:
            print("âš ï¸  é¢„æœŸçš„é”™è¯¯å“åº”ï¼ˆå› ä¸ºæ²¡æœ‰çœŸå®MCPæœåŠ¡å™¨ï¼‰")
        else:
            print("âœ… å·¥å…·è°ƒç”¨æˆåŠŸ")

    except Exception as e:
        print(f"âš ï¸  å·¥å…·è°ƒç”¨å¼‚å¸¸: {e}")

    print("âœ… ä¼˜åŒ–åçš„callMCPToolæµ‹è¯•é€šè¿‡")


async def test_execute_mcp_tool_calls():
    """æµ‹è¯•æ‰¹é‡æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨"""
    print("\n=== æµ‹è¯•2: æ‰¹é‡æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨ ===")

    # è®¾ç½®æœåŠ¡å™¨å’Œå·¥å…·
    server = create_mock_server()
    register_server_config(server)
    tools = create_mock_tools()

    # æ¨¡æ‹ŸLLMå“åº”åŒ…å«å·¥å…·è°ƒç”¨
    llm_response = """
    æˆ‘æ¥å¸®ä½ æœç´¢ç›¸å…³çš„å­¦æœ¯è®ºæ–‡ã€‚

    <tool_use>
    <tool_name>search_arxiv</tool_name>
    <parameters>
    {
        "query": "machine learning transformers",
        "max_results": 3
    }
    </parameters>
    </tool_use>
    """

    # è§£æå·¥å…·è°ƒç”¨
    tool_calls = parse_tool_use(llm_response, tools)
    print(f"è§£æåˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")

    # å®šä¹‰è¿›åº¦å›è°ƒ
    def progress_callback(message: str):
        print(f"  ğŸ“¡ {message}")

    # æ‰¹é‡æ‰§è¡Œå·¥å…·è°ƒç”¨
    results = await execute_mcp_tool_calls(tool_calls, tools, progress_callback)

    print(f"âœ… æ‰¹é‡æ‰§è¡Œå®Œæˆï¼Œè·å¾— {len(results)} ä¸ªç»“æœ")
    for i, result in enumerate(results):
        print(f"  ç»“æœ {i+1}: é”™è¯¯={result.isError}, å†…å®¹é•¿åº¦={len(result.content)}")

    assert len(results) == len(tool_calls)
    print("âœ… æ‰¹é‡æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨æµ‹è¯•é€šè¿‡")


async def test_ipc_communication():
    """æµ‹è¯•IPCé€šä¿¡æœºåˆ¶"""
    print("\n=== æµ‹è¯•3: IPCé€šä¿¡æœºåˆ¶ ===")

    # è®¾ç½®æœåŠ¡å™¨
    server = create_mock_server()

    # æµ‹è¯•æ·»åŠ æœåŠ¡å™¨
    success = await window_api_mcp.addServer(server)
    print(f"âœ… æ·»åŠ æœåŠ¡å™¨: {success}")
    assert success

    # æµ‹è¯•è·å–å·¥å…·åˆ—è¡¨
    tools = await window_api_mcp.listTools(server)
    print(f"âœ… è·å–å·¥å…·åˆ—è¡¨: {len(tools)} ä¸ªå·¥å…·")

    # æµ‹è¯•å·¥å…·è°ƒç”¨
    if tools:
        tool_request = {
            "server": server,
            "name": tools[0].name,
            "args": {"query": "test", "max_results": 1},
        }

        response = await window_api_mcp.callTool(tool_request)
        print(f"âœ… IPCå·¥å…·è°ƒç”¨: é”™è¯¯={response.isError}")
        assert isinstance(response, MCPCallToolResponse)

    # æµ‹è¯•æœåŠ¡å™¨ç®¡ç†
    restart_result = await window_api_mcp.restartServer(server.id)
    print(f"âœ… é‡å¯æœåŠ¡å™¨: {restart_result}")

    remove_result = await window_api_mcp.removeServer(server.id)
    print(f"âœ… ç§»é™¤æœåŠ¡å™¨: {remove_result}")

    print("âœ… IPCé€šä¿¡æœºåˆ¶æµ‹è¯•é€šè¿‡")


async def test_complete_workflow():
    """æµ‹è¯•å®Œæ•´çš„MCPå·¥ä½œæµç¨‹"""
    print("\n=== æµ‹è¯•4: å®Œæ•´MCPå·¥ä½œæµç¨‹ ===")

    # è®¾ç½®æœåŠ¡å™¨å’Œå·¥å…·
    server = create_mock_server()
    register_server_config(server)
    tools = create_mock_tools()

    # åˆ›å»ºåˆå§‹æ¶ˆæ¯
    messages = [
        ChatMessage(
            role="system", content="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œå¯ä»¥ä½¿ç”¨æä¾›çš„å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ã€‚"
        ),
        ChatMessage(
            role="user", content="è¯·å¸®æˆ‘æœç´¢å…³äºæœºå™¨å­¦ä¹ å˜æ¢å™¨çš„æœ€æ–°ç ”ç©¶è®ºæ–‡ã€‚"
        ),
    ]

    # å®šä¹‰è¿›åº¦å›è°ƒ
    def progress_callback(message: str):
        print(f"  ğŸ”„ {message}")

    print("å¼€å§‹å®Œæ•´å·¥ä½œæµç¨‹...")

    try:
        # æ‰§è¡Œå®Œæ•´å·¥ä½œæµç¨‹
        final_response = await complete_mcp_workflow(
            messages=messages,
            mcp_tools=tools,
            max_iterations=2,
            on_progress=progress_callback,
        )

        print("âœ… å·¥ä½œæµç¨‹å®Œæˆ")
        print(f"  æœ€ç»ˆå“åº”è§’è‰²: {final_response.message.role}")
        print(f"  å“åº”å†…å®¹é•¿åº¦: {len(final_response.message.content)}")
        print(
            f"  å·¥å…·è°ƒç”¨æ•°é‡: {len(final_response.message.tool_calls) if final_response.message.tool_calls else 0}"
        )

        # éªŒè¯å“åº”
        assert final_response.message.role == "assistant"
        assert len(final_response.message.content) > 0

        print(
            f"[éªŒè¯] complete_mcp_workflowæ‰§è¡ŒæˆåŠŸ: "
            f"{final_response.message.content[:100]}"
        )

    except Exception as e:
        print(f"âš ï¸  å·¥ä½œæµç¨‹å¼‚å¸¸: {e}")
        # è¿™æ˜¯é¢„æœŸçš„ï¼Œå› ä¸ºæ²¡æœ‰çœŸå®çš„LLM API

    print("âœ… å®Œæ•´MCPå·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡")


async def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\n=== æµ‹è¯•5: é”™è¯¯å¤„ç† ===")

    tools = create_mock_tools()

    # æµ‹è¯•å·¥å…·æœªæ‰¾åˆ°
    try:
        response = await callMCPTool("unknown_tool", {"param": "value"}, tools)
        assert response.isError
        assert "Tool not found" in response.content[0]["text"]
        print("âœ… å·¥å…·æœªæ‰¾åˆ°é”™è¯¯å¤„ç†æ­£ç¡®")
    except Exception as e:
        print(f"âš ï¸  é”™è¯¯å¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")

    # æµ‹è¯•æœåŠ¡å™¨æœªæ‰¾åˆ°
    try:
        # åˆ›å»ºä¸€ä¸ªæ²¡æœ‰å¯¹åº”æœåŠ¡å™¨çš„å·¥å…·
        fake_tool = MCPTool(
            id="fake",
            name="fake_tool",
            description="Fake tool",
            inputSchema={},
            server_id="fake_server",
            server_name="Fake Server",
        )
        response = await callMCPTool("fake_tool", {}, [fake_tool])
        assert response.isError
        assert "Server not found" in response.content[0]["text"]
        print("âœ… æœåŠ¡å™¨æœªæ‰¾åˆ°é”™è¯¯å¤„ç†æ­£ç¡®")
    except Exception as e:
        print(f"âš ï¸  é”™è¯¯å¤„ç†æµ‹è¯•å¼‚å¸¸: {e}")

    print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")


async def test_data_flow():
    """æµ‹è¯•æ•°æ®æµè½¬"""
    print("\n=== æµ‹è¯•6: æ•°æ®æµè½¬éªŒè¯ ===")

    # è®¾ç½®ç¯å¢ƒ
    server = create_mock_server()
    register_server_config(server)
    tools = create_mock_tools()

    # Step 1: æ¨¡æ‹ŸLLMç”ŸæˆåŒ…å«å·¥å…·è°ƒç”¨çš„å“åº”
    llm_response_content = """
    æˆ‘éœ€è¦æœç´¢ä¸€äº›å­¦æœ¯è®ºæ–‡æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚

    <tool_use>
    <tool_name>search_arxiv</tool_name>
    <parameters>
    {
        "query": "neural networks deep learning",
        "max_results": 5
    }
    </parameters>
    </tool_use>
    """

    print("1ï¸âƒ£ LLMç”Ÿæˆå“åº”ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ï¼‰")
    print(f"   å“åº”é•¿åº¦: {len(llm_response_content)} å­—ç¬¦")

    # Step 2: è§£æå·¥å…·è°ƒç”¨å‚æ•°
    parsed_calls = parse_tool_use(llm_response_content, tools)
    print(f"2ï¸âƒ£ è§£æå·¥å…·è°ƒç”¨: {len(parsed_calls)} ä¸ª")

    if parsed_calls:
        first_call = parsed_calls[0]
        print(f"   å·¥å…·åç§°: {first_call.tool.name}")
        print(f"   å‚æ•°: {first_call.tool.arguments}")

        # Step 3: ä½¿ç”¨å‚æ•°è°ƒç”¨å®é™…MCPå·¥å…·
        print("3ï¸âƒ£ æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨")
        tool_result = await callMCPTool(
            first_call.tool.name, first_call.tool.arguments, tools
        )

        print(f"   æ‰§è¡Œç»“æœ: é”™è¯¯={tool_result.isError}")
        print(f"   ç»“æœå†…å®¹: {len(tool_result.content)} é¡¹")

        # Step 4: ç»“æœå¯ä»¥è¿”å›ç»™LLMç»§ç»­å¤„ç†
        print("4ï¸âƒ£ ç»“æœè¿”å›ç»™LLMï¼ˆæ¨¡æ‹Ÿï¼‰")
        result_text = (
            tool_result.content[0].get("text", "") if tool_result.content else ""
        )
        print(f"   ç»“æœæ–‡æœ¬é•¿åº¦: {len(result_text)} å­—ç¬¦")

        print("âœ… å®Œæ•´æ•°æ®æµè½¬éªŒè¯æˆåŠŸ")
    else:
        print("âŒ æœªè§£æåˆ°å·¥å…·è°ƒç”¨")

    print("âœ… æ•°æ®æµè½¬éªŒè¯æµ‹è¯•é€šè¿‡")


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹Step7ä¼˜åŒ–æµ‹è¯•")
    print("=" * 50)

    try:
        await test_optimized_call_mcp_tool()
        await test_execute_mcp_tool_calls()
        await test_ipc_communication()
        await test_complete_workflow()
        await test_error_handling()
        await test_data_flow()

        print("\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰Step7ä¼˜åŒ–æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ ä¼˜åŒ–åçš„åŠŸèƒ½æ€»ç»“ï¼š")
        print("âœ… callMCPTool: ä½¿ç”¨å®é™…å‚æ•°è°ƒç”¨MCPå·¥å…·")
        print("âœ… execute_mcp_tool_calls: æ‰¹é‡æ‰§è¡Œå·¥å…·è°ƒç”¨")
        print("âœ… complete_mcp_workflow: å®Œæ•´çš„LLM+MCPå·¥ä½œæµç¨‹")
        print("âœ… IPCé€šä¿¡: æ¨¡æ‹ŸCherry Studioçš„IPCæœºåˆ¶")
        print("âœ… é”™è¯¯å¤„ç†: å¥å£®çš„å¼‚å¸¸å¤„ç†")
        print("âœ… æ•°æ®æµè½¬: LLM â†’ å‚æ•°è§£æ â†’ MCPè°ƒç”¨ â†’ ç»“æœè¿”å›")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
