"""
Step6æµ‹è¯•ï¼šè§£æLLMå“åº”ä¸­çš„å·¥å…·è°ƒç”¨å¹¶æ‰§è¡Œ
æµ‹è¯•parseAndCallToolsåŠŸèƒ½çš„å®Œæ•´å®ç°
"""

import asyncio
import logging
from typing import List

from chat_mcp import (
    parse_tool_use,
    parse_and_call_tools,
    call_mcp_tool,
    upsert_mcp_tool_response,
    register_server_config,
    MCPTool,
    MCPServer,
    MCPToolCall,
    MCPToolResponse,
    MCPCallToolResponse,
    ChatMessage,
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


def create_mock_tools() -> List[MCPTool]:
    """åˆ›å»ºæ¨¡æ‹Ÿçš„MCPå·¥å…·"""
    return [
        MCPTool(
            id="tool_1",
            name="search_arxiv",
            description="Search for academic papers on arXiv",
            inputSchema={
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "Search query"},
                    "max_results": {
                        "type": "integer",
                        "description": "Maximum results",
                        "default": 10,
                    },
                },
                "required": ["query"],
            },
            server_id="arxiv_server",
            server_name="ArXiv MCP Server",
        ),
        MCPTool(
            id="tool_2",
            name="get_weather",
            description="Get current weather information",
            inputSchema={
                "type": "object",
                "properties": {
                    "location": {"type": "string", "description": "Location name"},
                    "units": {
                        "type": "string",
                        "description": "Temperature units",
                        "default": "celsius",
                    },
                },
                "required": ["location"],
            },
            server_id="weather_server",
            server_name="Weather MCP Server",
        ),
    ]


def create_mock_server_configs() -> List[MCPServer]:
    """åˆ›å»ºæ¨¡æ‹Ÿçš„æœåŠ¡å™¨é…ç½®"""
    return [
        MCPServer(
            id="arxiv_server",
            name="ArXiv MCP Server",
            command="npx",
            args=["-y", "@modelcontextprotocol/server-arxiv"],
        ),
        MCPServer(
            id="weather_server",
            name="Weather MCP Server",
            command="python",
            args=["-m", "weather_server"],
        ),
    ]


async def test_parse_tool_use():
    """æµ‹è¯•å·¥å…·è°ƒç”¨è§£æåŠŸèƒ½"""
    print("\n=== æµ‹è¯•1: å·¥å…·è°ƒç”¨è§£æ ===")

    # æ¨¡æ‹ŸLLMå“åº”åŒ…å«å·¥å…·è°ƒç”¨
    llm_response = """
    æˆ‘æ¥å¸®ä½ æœç´¢ç›¸å…³çš„å­¦æœ¯è®ºæ–‡ã€‚

    <tool_use>
    <tool_name>search_arxiv</tool_name>
    <parameters>
    {
        "query": "machine learning transformers",
        "max_results": 5
    }
    </parameters>
    </tool_use>

    è®©æˆ‘ä¹ŸæŸ¥çœ‹ä¸€ä¸‹å¤©æ°”ä¿¡æ¯ï¼š

    <tool_use>
    <tool_name>get_weather</tool_name>
    <parameters>
    {
        "location": "Beijing"
    }
    </parameters>
    </tool_use>
    """

    tools = create_mock_tools()
    parsed_tools = parse_tool_use(llm_response, tools)

    print(f"âœ… è§£æåˆ° {len(parsed_tools)} ä¸ªå·¥å…·è°ƒç”¨")
    for i, tool_result in enumerate(parsed_tools):
        print(f"  å·¥å…· {i+1}: {tool_result.tool.name}")
        print(f"    å‚æ•°: {tool_result.tool.arguments}")

    assert len(parsed_tools) == 2
    assert parsed_tools[0].tool.name == "search_arxiv"
    assert parsed_tools[1].tool.name == "get_weather"
    print("âœ… å·¥å…·è°ƒç”¨è§£ææµ‹è¯•é€šè¿‡")


async def test_mock_call_mcp_tool():
    """æµ‹è¯•æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨"""
    print("\n=== æµ‹è¯•2: æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨ ===")

    # æ³¨å†ŒæœåŠ¡å™¨é…ç½®
    servers = create_mock_server_configs()
    for server in servers:
        register_server_config(server)

    tools = create_mock_tools()

    # åˆ›å»ºå·¥å…·è°ƒç”¨
    tool_call = MCPToolCall(
        id="call_1",
        name="search_arxiv",
        arguments={"query": "machine learning", "max_results": 3},
    )

    # æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨ï¼ˆè¿™é‡Œä¼šå¤±è´¥ï¼Œå› ä¸ºæ²¡æœ‰çœŸå®çš„MCPæœåŠ¡å™¨ï¼‰
    try:
        response = await call_mcp_tool(tool_call, tools)
        print(f"âœ… å·¥å…·è°ƒç”¨å“åº”: {response.isError}")
        print(f"  å†…å®¹: {response.content[0].get('text', '')[:100]}...")
    except Exception as e:
        print(f"âš ï¸  é¢„æœŸçš„å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
        # åˆ›å»ºæ¨¡æ‹Ÿå“åº”
        response = MCPCallToolResponse(
            content=[
                {"type": "text", "text": "æ¨¡æ‹Ÿæœç´¢ç»“æœï¼šæ‰¾åˆ°3ç¯‡å…³äºæœºå™¨å­¦ä¹ çš„è®ºæ–‡"}
            ],
            isError=False,
        )
        print(f"âœ… ä½¿ç”¨æ¨¡æ‹Ÿå“åº”: {response.content[0]['text']}")


async def test_upsert_tool_response():
    """æµ‹è¯•å·¥å…·å“åº”æ›´æ–°åŠŸèƒ½"""
    print("\n=== æµ‹è¯•3: å·¥å…·å“åº”æ›´æ–° ===")

    tool_responses: List[MCPToolResponse] = []

    # åˆ›å»ºå·¥å…·è°ƒç”¨
    tool_call = MCPToolCall(id="call_1", name="search_arxiv", arguments={"query": "AI"})

    # åˆ›å»ºåˆå§‹å“åº”
    initial_response = MCPToolResponse(
        id="response_1", tool=tool_call, status="invoking"
    )

    # æ¨¡æ‹Ÿæµå¼å›è°ƒ
    def mock_on_chunk(chunk):
        print(f"  ğŸ“¡ æµå¼æ›´æ–°: {chunk.get('text', '')}")

    # æ’å…¥åˆå§‹å“åº”
    upsert_mcp_tool_response(tool_responses, initial_response, mock_on_chunk)
    assert len(tool_responses) == 1
    assert tool_responses[0].status == "invoking"

    # æ›´æ–°å“åº”çŠ¶æ€
    completed_response = MCPToolResponse(
        id="response_1",
        tool=tool_call,
        status="done",
        content=[{"type": "text", "text": "æœç´¢å®Œæˆ"}],
    )

    upsert_mcp_tool_response(tool_responses, completed_response, mock_on_chunk)
    assert len(tool_responses) == 1  # åº”è¯¥æ˜¯æ›´æ–°è€Œä¸æ˜¯æ–°å¢
    assert tool_responses[0].status == "done"

    print("âœ… å·¥å…·å“åº”æ›´æ–°æµ‹è¯•é€šè¿‡")


async def test_parse_and_call_tools_mock():
    """æµ‹è¯•å®Œæ•´çš„è§£æå’Œè°ƒç”¨æµç¨‹ï¼ˆæ¨¡æ‹Ÿç‰ˆæœ¬ï¼‰"""
    print("\n=== æµ‹è¯•4: å®Œæ•´è§£æå’Œè°ƒç”¨æµç¨‹ï¼ˆæ¨¡æ‹Ÿï¼‰ ===")

    # æ³¨å†ŒæœåŠ¡å™¨é…ç½®
    servers = create_mock_server_configs()
    for server in servers:
        register_server_config(server)

    tools = create_mock_tools()

    # LLMå“åº”åŒ…å«å·¥å…·è°ƒç”¨
    llm_response = """
    <tool_use>
    <tool_name>search_arxiv</tool_name>
    <parameters>
    {
        "query": "neural networks"
    }
    </parameters>
    </tool_use>
    """

    tool_responses: List[MCPToolResponse] = []

    def mock_on_chunk(chunk):
        print(f"  ğŸ“¡ {chunk.get('text', '')}")

    # æ¨¡æ‹Ÿconvert_to_messageå‡½æ•°
    def mock_convert_to_message(
        tool_call_id: str, response: MCPCallToolResponse, is_vision_model: bool = False
    ) -> ChatMessage:
        text_content = ""
        for content_item in response.content:
            if content_item.get("type") == "text":
                text_content += content_item.get("text", "")

        return ChatMessage(
            role="tool",
            content=text_content,
            tool_call_id=tool_call_id,
            metadata={"tool_response": response.model_dump()},
        )

    try:
        # æ‰§è¡Œè§£æå’Œè°ƒç”¨
        result_messages = await parse_and_call_tools(
            content=llm_response,
            tool_responses=tool_responses,
            on_chunk=mock_on_chunk,
            idx=0,
            convert_to_message=mock_convert_to_message,
            mcp_tools=tools,
            is_vision_model=False,
        )

        print(f"âœ… ç”Ÿæˆäº† {len(result_messages)} ä¸ªç»“æœæ¶ˆæ¯")
        for msg in result_messages:
            print(f"  æ¶ˆæ¯è§’è‰²: {msg.role}")
            print(f"  æ¶ˆæ¯å†…å®¹: {msg.content[:100]}...")

    except Exception as e:
        print(f"âš ï¸  é¢„æœŸçš„è°ƒç”¨å¤±è´¥: {e}")
        print("âœ… é”™è¯¯å¤„ç†æ­£å¸¸å·¥ä½œ")


async def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\n=== æµ‹è¯•5: è¾¹ç•Œæƒ…å†µ ===")

    # æµ‹è¯•ç©ºå†…å®¹
    empty_result = parse_tool_use("", [])
    assert len(empty_result) == 0
    print("âœ… ç©ºå†…å®¹å¤„ç†æ­£ç¡®")

    # æµ‹è¯•æ— æ•ˆJSON
    invalid_json_content = """
    <tool_use>
    <tool_name>test_tool</tool_name>
    <parameters>
    { invalid json }
    </parameters>
    </tool_use>
    """

    invalid_result = parse_tool_use(invalid_json_content, [])
    assert len(invalid_result) == 0  # åº”è¯¥è·³è¿‡æ— æ•ˆçš„å·¥å…·è°ƒç”¨
    print("âœ… æ— æ•ˆJSONå¤„ç†æ­£ç¡®")

    # æµ‹è¯•ä¸å­˜åœ¨çš„å·¥å…·
    unknown_tool_content = """
    <tool_use>
    <tool_name>unknown_tool</tool_name>
    <parameters>
    {"param": "value"}
    </parameters>
    </tool_use>
    """

    tools = create_mock_tools()
    unknown_result = parse_tool_use(unknown_tool_content, tools)
    assert len(unknown_result) == 1  # åº”è¯¥è§£ææˆåŠŸï¼Œä½†å·¥å…·ä¸å­˜åœ¨
    print("âœ… æœªçŸ¥å·¥å…·å¤„ç†æ­£ç¡®")


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹Step6æµ‹è¯•ï¼šè§£æLLMå“åº”ä¸­çš„å·¥å…·è°ƒç”¨å¹¶æ‰§è¡Œ")

    try:
        await test_parse_tool_use()
        await test_mock_call_mcp_tool()
        await test_upsert_tool_response()
        await test_parse_and_call_tools_mock()
        await test_edge_cases()

        print("\nğŸ‰ Step6æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ Step6åŠŸèƒ½æ€»ç»“ï¼š")
        print("âœ… parse_tool_use: è§£æXMLæ ¼å¼çš„å·¥å…·è°ƒç”¨")
        print("âœ… call_mcp_tool: æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨")
        print("âœ… upsert_mcp_tool_response: ç®¡ç†å·¥å…·å“åº”çŠ¶æ€")
        print("âœ… parse_and_call_tools: å®Œæ•´çš„è§£æå’Œæ‰§è¡Œæµç¨‹")
        print("âœ… é”™è¯¯å¤„ç†: ä¼˜é›…å¤„ç†å„ç§å¼‚å¸¸æƒ…å†µ")
        print("âœ… æµå¼æ”¯æŒ: æ”¯æŒæµå¼å“åº”å›è°ƒ")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
